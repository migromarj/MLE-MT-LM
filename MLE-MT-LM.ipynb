{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bardapi import BardCookies\n",
    "from sydney import SydneyClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('summarize', 'facebook/bart-large-cnn'),\n",
    "    ('summarize', 'google/pegasus-large'),\n",
    "    ('summarize', 'marianna13/flan-t5-base-summarization'),\n",
    "    ('toxic', 's-nlp/roberta_toxicity_classifier'),\n",
    "    ('toxic', 'citizenlab/distilbert-base-multilingual-cased-toxicity', 'inputs'),\n",
    "    ('toxic', 'martin-ha/toxic-comment-model'),\n",
    "    ('spam', 'rafacost/bert_base_pt_en_cased_email_spam'),\n",
    "    ('spam', 'h-e-l-l-o/email-spam-classification-merged'),\n",
    "    ('spam', 'dima806/email-spam-detection-roberta'),\n",
    "    ('translate', 't5-base'),\n",
    "    ('translate', 'allenai/wmt16-en-de-12-1'),\n",
    "    ('translate', 'facebook/wmt19-en-de'),\n",
    "    ('fillmask', 'bert-base-uncased', '[MASK]'),\n",
    "    ('fillmask', 'vinai/bertweet-base', '<mask>'),\n",
    "    ('fillmask', 'roberta-base', '<mask>'),\n",
    "]\n",
    "\n",
    "# ('q&a', 'deepset/roberta-base-squad2'),\n",
    "# ('q&a', 'timpal0l/mdeberta-v3-base-squad2'),\n",
    "# ('q&a', 'bert-large-uncased-whole-word-masking-finetuned-squad'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_to_model(model, input):\n",
    "\n",
    "    BASE_URL = \"https://api-inference.huggingface.co/models/\"\n",
    "    headers = {\"Authorization\": f\"Bearer {os.getenv('HUGGING_FACE_API_KEY')}\"}\n",
    "    new_input = input\n",
    "    parameters = {}\n",
    "\n",
    "    if model[0] == 'fillmask':\n",
    "        new_input = input.replace('<mask>', model[2])\n",
    "    elif model[0] == 'translate':\n",
    "        parameters = {\"src_lang\": \"en_XX\", \"tgt_lang\": \"tgt_XX\"}\n",
    "\n",
    "    query = {\"inputs\": new_input, \"wait_for_model\": True, \"parameters\":parameters}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(BASE_URL + model[1], json=query, headers=headers)\n",
    "    except Exception as exception:\n",
    "        print(exception)\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Das Handtuch ist 324 Meter gro√ü.'}]\n"
     ]
    }
   ],
   "source": [
    "res = request_to_model(models[10], \"The tower is 324 metres (1,063 ft) tall\") # \"The goal of life is <mask>.\"\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bing Chat was launched on **February 7, 2023** [^2^]. It was later renamed to Microsoft Copilot [^1^] and integrated directly into the search engine.\n"
     ]
    }
   ],
   "source": [
    "async with SydneyClient() as sydney:\n",
    "    response = await sydney.ask(\"When was Bing Chat released?\", citations=False)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a large language model, also known as a conversational AI or chatbot trained to be informative and comprehensive. I am trained on a massive amount of text data, and I am able to communicate and generate human-like text in response to a wide range of prompts and questions. For example, I can provide summaries of factual topics or create stories.\n",
      "\n",
      "The model that I am trained on is called PaLM 2, and it is Google's most advanced large language model. PaLM 2 was unveiled at Google I/O 2023, and it is capable of performing many kinds of tasks, including\n",
      "* Understanding and responding to natural language\n",
      "* Generating different creative text formats of text content, like poems, code, scripts, musical pieces, email, letters, etc.\n",
      "* Answering your questions in an informative way, even if they are open ended, challenging, or strange.\n",
      "* Translating languages\n",
      "* Writing different kinds of creative content\n",
      "\n",
      "I am still under development, but I have learned to perform many kinds of tasks. I am still learning, and I am always working to improve my abilities.\n"
     ]
    }
   ],
   "source": [
    "cookie_dict = {\n",
    "    \"__Secure-1PSID\": os.getenv('SECURE_1PSID'),\n",
    "    \"__Secure-1PSIDTS\": os.getenv('SECURE_1PSIDTS'),\n",
    "    \"__Secure-1PSIDCC\": os.getenv('SECURE_1PSIDCC'),\n",
    "}\n",
    "\n",
    "bard = BardCookies(cookie_dict=cookie_dict)\n",
    "print(bard.get_answer(\"WHAT MODEL ARE YOU USING?\")['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
