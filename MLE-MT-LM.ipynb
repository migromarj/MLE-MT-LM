{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bardapi import BardCookies\n",
    "from sydney import SydneyClient\n",
    "from dotenv import load_dotenv\n",
    "import markdown\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('summarize', 'facebook/bart-large-cnn'),\n",
    "    ('summarize', 'google/pegasus-large'),\n",
    "    ('summarize', 'marianna13/flan-t5-base-summarization'),\n",
    "    ('toxic', 's-nlp/roberta_toxicity_classifier'),\n",
    "    ('toxic', 'citizenlab/distilbert-base-multilingual-cased-toxicity', 'inputs'),\n",
    "    ('toxic', 'martin-ha/toxic-comment-model'),\n",
    "    ('spam', 'rafacost/bert_base_pt_en_cased_email_spam'),\n",
    "    ('spam', 'h-e-l-l-o/email-spam-classification-merged'),\n",
    "    ('spam', 'dima806/email-spam-detection-roberta'),\n",
    "    ('translate', 't5-base'),\n",
    "    ('translate', 'allenai/wmt16-en-de-12-1'),\n",
    "    ('translate', 'facebook/wmt19-en-de'),\n",
    "    ('fillmask', 'bert-base-uncased', '[MASK]'),\n",
    "    ('fillmask', 'vinai/bertweet-base', '<mask>'),\n",
    "    ('fillmask', 'roberta-base', '<mask>'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_to_model(model, input):\n",
    "\n",
    "    BASE_URL = \"https://api-inference.huggingface.co/models/\"\n",
    "    headers = {\"Authorization\": f\"Bearer {os.getenv('HUGGING_FACE_API_KEY')}\"}\n",
    "    new_input = input\n",
    "    parameters = {}\n",
    "\n",
    "    if model[0] == 'fillmask':\n",
    "        new_input = input.replace('<mask>', model[2])\n",
    "    elif model[0] == 'translate':\n",
    "        parameters = {\"src_lang\": \"en_XX\", \"tgt_lang\": \"tgt_XX\"}\n",
    "\n",
    "    query = {\"inputs\": new_input, \"wait_for_model\": True, \"parameters\":parameters}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(BASE_URL + model[1], json=query, headers=headers)\n",
    "    except Exception as exception:\n",
    "        print(exception)\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Das Handtuch ist 324 Meter groß.'}]\n"
     ]
    }
   ],
   "source": [
    "res = request_to_model(models[10], \"The tower is 324 metres (1,063 ft) tall\") # \"The goal of life is <mask>.\"\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_plain_text(input_text):\n",
    "    input_text = re.sub(r'\\[\\^\\d+\\^\\]', '', input_text)\n",
    "    plain_text = markdown.markdown(input_text, output_format='html')\n",
    "    plain_text = re.sub(r'<[^>]*>\\s*', '', plain_text)\n",
    "    return plain_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def request_to_bing(question, type=\"q&a\"):\n",
    "\n",
    "    prompt = \"\"\n",
    "\n",
    "    if (type == \"q&a\"):\n",
    "        prompt = \"Answer me the following question in plain text without using quotes: \"\n",
    "    elif (type == \"change_order\"):\n",
    "        prompt = \"Change the order of the next sentence: \"\n",
    "\n",
    "    async with SydneyClient() as sydney:\n",
    "        response = await sydney.ask(prompt + question, citations=False)\n",
    "        response = convert_to_plain_text(response)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bing Chat was released on February 8th, 2023.\n"
     ]
    }
   ],
   "source": [
    "response = await request_to_bing(\"When was Bing Chat released?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I can help you with that. Here's the sentence with the order changed: \"I live in Spain. How many people live in Berlin?\" I hope that helps!.\n"
     ]
    }
   ],
   "source": [
    "response = await request_to_bing(\"How many people live in Berlin? I live in Spain\", \"change_order\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_to_bard(question):\n",
    "\n",
    "    cookie_dict = {\n",
    "        \"__Secure-1PSID\": os.getenv('SECURE_1PSID'),\n",
    "        \"__Secure-1PSIDTS\": os.getenv('SECURE_1PSIDTS'),\n",
    "        \"__Secure-1PSIDCC\": os.getenv('SECURE_1PSIDCC'),\n",
    "    }\n",
    "\n",
    "    bard = BardCookies(cookie_dict=cookie_dict)\n",
    "    response = bard.get_answer(question)['content']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bard was initially announced on February 17, 2023, and released in a limited capacity on March 21, 2023. It was upgraded to PaLM and then to Gemini in 2023.\n"
     ]
    }
   ],
   "source": [
    "print(request_to_bard(\"When was Bard released?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERTURBACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sustituir_caracteres(cadena, nivel):\n",
    "    if nivel < 1 or nivel > 10:\n",
    "        return \"El nivel debe estar entre 1 y 10.\"\n",
    "    \n",
    "    caracteres = list(cadena)\n",
    "    indices_a_sustituir = [i for i in range(len(caracteres)) if caracteres[i] in string.ascii_letters]\n",
    "    num_caracteres_a_sustituir = int(len(indices_a_sustituir) * nivel / 10)\n",
    "    indices_a_sustituir = random.sample(indices_a_sustituir, num_caracteres_a_sustituir)\n",
    "    \n",
    "    for indice in indices_a_sustituir:\n",
    "        caracteres[indice] = random.choice(string.ascii_letters)\n",
    "    \n",
    "    return ''.join(caracteres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, ¿Hómo estág? Ha pasado bastante tiempe desde que tu y yo nSs conocjmos\n"
     ]
    }
   ],
   "source": [
    "print(sustituir_caracteres(\"Hola, ¿cómo estás? Ha pasado bastante tiempo desde que tu y yo nos conocimos\", 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
