{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguel/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/miguel/Library/Python/3.9/lib/python/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package punkt to /Users/miguel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import nltk\n",
    "from functions.metamorphic import calculate_M_ASR, calculate_M_ASR_without_Bing\n",
    "from functions.perturbations import delete_characters, add_characters, add_random_words, remplace_named_entities, replace_characters, replace_words_with_antonyms, replace_words_with_synonyms, delete_sentences\n",
    "from functions.models import request_to_bing\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11XHk2dHBh87rF9cZKjg-zQjk_NqDKbUqol32Wb4df35Q2aqy1sw514p2RN7sq9fHrgga_Pt39FVmWW0rHFlyQbvTdQkeOusk7zHTTNnGnwqbCFznhJJBDWv6APf1a7liMLkfXu6A7cPdXpPNsEWEPR4wzuOGZ_U1ztJGYiHrotj4iaOmbeS_bNVFkSJdK3KH1UmgWPRWpAw3IApbEvE5guEkqlSySV3O_4qS1wWYizs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"BING_U_COOKIE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "CreateConversationException",
     "evalue": "Failed to create conversation, received status: 404",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCreateConversationException\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;01mawait\u001b[39;00m request_to_bing(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the capital of Spain?\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/GitHubProjects/MLE-MT-LM/functions/models.py:87\u001b[0m, in \u001b[0;36mrequest_to_bing\u001b[0;34m(first_question, second_question, type, prompt, iterations)\u001b[0m\n\u001b[1;32m     85\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m sydney1\u001b[38;5;241m.\u001b[39mask(prompt \u001b[38;5;241m+\u001b[39m first_question \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m second_question, citations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m SydneyClient(style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m sydney2:\n\u001b[1;32m     88\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m sydney2\u001b[38;5;241m.\u001b[39mask(prompt \u001b[38;5;241m+\u001b[39m first_question, citations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     90\u001b[0m response \u001b[38;5;241m=\u001b[39m convert_to_plain_text(response)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sydney/sydney.py:93\u001b[0m, in \u001b[0;36mSydneyClient.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SydneyClient:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_conversation()\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sydney/sydney.py:427\u001b[0m, in \u001b[0;36mSydneyClient.start_conversation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mget(BING_CREATE_CONVERSATION_URL) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m--> 427\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CreateConversationException(\n\u001b[1;32m    428\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to create conversation, received status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m         )\n\u001b[1;32m    431\u001b[0m     response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mCreateConversationException\u001b[0m: Failed to create conversation, received status: 404"
     ]
    }
   ],
   "source": [
    "print(await request_to_bing(\"What is the capital of Spain?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de modelos con BING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('summarize', 'facebook/bart-large-cnn'),\n",
    "    ('summarize', 'google/pegasus-large'),\n",
    "    ('summarize', 'marianna13/flan-t5-base-summarization'),\n",
    "    ('toxic', 's-nlp/roberta_toxicity_classifier'),\n",
    "    ('toxic', 'citizenlab/distilbert-base-multilingual-cased-toxicity', 'inputs'),\n",
    "    ('toxic', 'martin-ha/toxic-comment-model'),\n",
    "    ('spam', 'rafacost/bert_base_pt_en_cased_email_spam'),\n",
    "    ('spam', 'h-e-l-l-o/email-spam-classification-merged'),\n",
    "    ('spam', 'dima806/email-spam-detection-roberta'),\n",
    "    ('translate', 't5-base'),\n",
    "    ('translate', 'allenai/wmt16-en-de-12-1'),\n",
    "    ('translate', 'facebook/wmt19-en-de'),\n",
    "    ('fillmask', 'bert-base-uncased', '[MASK]'),\n",
    "    ('fillmask', 'vinai/bertweet-base', '<mask>'),\n",
    "    ('fillmask', 'roberta-base', '<mask>'),\n",
    "]\n",
    "\n",
    "models_summarize = [models[0], models[1]]\n",
    "models_toxic = [models[3], models[4]]\n",
    "models_spam = [models[6], models[7]]\n",
    "models_translate = [models[9], models[10]]\n",
    "models_fillmask = [models[13], models[14]]\n",
    "perturbations = [(delete_characters, False, 'delete_characters'), (replace_characters, False, 'replace_characters'), (add_characters, False, 'add_characters'),(replace_words_with_synonyms, False, 'replace_word_synonyms'), (replace_words_with_antonyms, True,'replace_word_antonyms'), (add_random_words, False,'add_random_words'), (remplace_named_entities, False,'remplace_named_entities')]\n",
    "atribbutes = [\"Robustness\", \"Non-determinism\", \"Fairness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def M_ASR(models, perturbations, attributes):\n",
    "    RESULTS = pd.DataFrame(columns=[\"Value\", \"Time\"])\n",
    "    for model in models:\n",
    "        m_type = model[0]\n",
    "        for perturbation in perturbations:\n",
    "            new_attibutes = attributes.copy() if m_type != \"summarize\" else atribbutes.copy()[:-1]\n",
    "            for attribute in new_attibutes:\n",
    "                print(model[0], model[1], perturbation[2], attribute)\n",
    "                M, ASR = await calculate_M_ASR(model, perturbation[0], attribute, perturbation[2], perturbation[1], iterations=1)\n",
    "                print(M, ASR)\n",
    "                RESULTS.loc[model[0] + \" - \" + model[1] + \" - \" + perturbation[2] + \" - \" + attribute] = [M, ASR]\n",
    "\n",
    "    return RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_results = await M_ASR(models_summarize, perturbations, atribbutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - delete_characters - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.264758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - delete_characters - Non-determinism</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.770170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - replace_characters - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.813684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - replace_characters - Non-determinism</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.727678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - add_characters - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.058627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - add_characters - Non-determinism</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.354026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - replace_words_with_synonyms - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.693539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - replace_words_with_synonyms - Non-determinism</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30.646007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - replace_words_with_antonyms - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.946164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - replace_words_with_antonyms - Non-determinism</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.091527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - add_random_words - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.860123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - add_random_words - Non-determinism</th>\n",
       "      <td>1.0</td>\n",
       "      <td>64.181294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - remplace_named_entities - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.530190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/bart-large-cnn - remplace_named_entities - Non-determinism</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.747387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - delete_characters - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.740884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - delete_characters - Non-determinism</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.845890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - replace_characters - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.251030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - replace_characters - Non-determinism</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.471408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - add_characters - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.717976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - add_characters - Non-determinism</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.868980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - replace_words_with_synonyms - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.250777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - replace_words_with_synonyms - Non-determinism</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28.295642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - replace_words_with_antonyms - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.397552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - replace_words_with_antonyms - Non-determinism</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.529598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - add_random_words - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>24.789065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - add_random_words - Non-determinism</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.954569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - remplace_named_entities - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.170593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/pegasus-large - remplace_named_entities - Non-determinism</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.238604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Value       Time\n",
       "facebook/bart-large-cnn - delete_characters - R...    1.0   8.264758\n",
       "facebook/bart-large-cnn - delete_characters - N...    1.0  17.770170\n",
       "facebook/bart-large-cnn - replace_characters - ...    0.0   7.813684\n",
       "facebook/bart-large-cnn - replace_characters - ...    1.0  21.727678\n",
       "facebook/bart-large-cnn - add_characters - Robu...    1.0  10.058627\n",
       "facebook/bart-large-cnn - add_characters - Non-...    1.0  31.354026\n",
       "facebook/bart-large-cnn - replace_words_with_sy...    1.0  14.693539\n",
       "facebook/bart-large-cnn - replace_words_with_sy...    0.0  30.646007\n",
       "facebook/bart-large-cnn - replace_words_with_an...    0.0  14.946164\n",
       "facebook/bart-large-cnn - replace_words_with_an...    0.0  27.091527\n",
       "facebook/bart-large-cnn - add_random_words - Ro...    0.0  15.860123\n",
       "facebook/bart-large-cnn - add_random_words - No...    1.0  64.181294\n",
       "facebook/bart-large-cnn - remplace_named_entiti...    1.0  14.530190\n",
       "facebook/bart-large-cnn - remplace_named_entiti...    0.0  24.747387\n",
       "google/pegasus-large - delete_characters - Robu...    1.0   8.740884\n",
       "google/pegasus-large - delete_characters - Non-...    0.0  17.845890\n",
       "google/pegasus-large - replace_characters - Rob...    1.0  10.251030\n",
       "google/pegasus-large - replace_characters - Non...    1.0  12.471408\n",
       "google/pegasus-large - add_characters - Robustness    0.0   8.717976\n",
       "google/pegasus-large - add_characters - Non-det...    0.0  18.868980\n",
       "google/pegasus-large - replace_words_with_synon...    0.0  13.250777\n",
       "google/pegasus-large - replace_words_with_synon...    1.0  28.295642\n",
       "google/pegasus-large - replace_words_with_anton...    1.0  13.397552\n",
       "google/pegasus-large - replace_words_with_anton...    0.0  27.529598\n",
       "google/pegasus-large - add_random_words - Robus...    1.0  24.789065\n",
       "google/pegasus-large - add_random_words - Non-d...    1.0  21.954569\n",
       "google/pegasus-large - remplace_named_entities ...    1.0  16.170593\n",
       "google/pegasus-large - remplace_named_entities ...    1.0  21.238604"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_results = await M_ASR(models_toxic, perturbations, atribbutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_results = await M_ASR(models_spam, perturbations, atribbutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_results = await M_ASR(models_translate, perturbations, atribbutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_masks_results = await M_ASR(models_fillmask, perturbations, atribbutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_masks_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de modelos sin BING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('summarize', 'facebook/bart-large-cnn'),\n",
    "    ('summarize', 'google/pegasus-large'),\n",
    "    ('summarize', 'marianna13/flan-t5-base-summarization'),\n",
    "    ('toxic', 's-nlp/roberta_toxicity_classifier'),\n",
    "    ('toxic', 'citizenlab/distilbert-base-multilingual-cased-toxicity', 'inputs'),\n",
    "    ('toxic', 'martin-ha/toxic-comment-model'),\n",
    "    ('spam', 'rafacost/bert_base_pt_en_cased_email_spam'), # Deleted by their owner\n",
    "    ('spam', 'h-e-l-l-o/email-spam-classification-merged'),\n",
    "    ('spam', 'dima806/email-spam-detection-roberta'),\n",
    "    ('translate', 't5-base'),\n",
    "    ('translate', 'allenai/wmt16-en-de-12-1'),\n",
    "    ('translate', 'facebook/wmt19-en-de'),\n",
    "    ('fillmask', 'bert-base-uncased', '[MASK]'),\n",
    "    ('fillmask', 'vinai/bertweet-base', '<mask>'),\n",
    "    ('fillmask', 'roberta-base', '<mask>'),\n",
    "]\n",
    "\n",
    "models_summarize = [models[0], models[1]]\n",
    "models_toxic = [models[3], models[4]]\n",
    "models_spam = [models[7], models[8]]\n",
    "models_translate = [models[9], models[10]]\n",
    "models_fillmask = [models[13], models[14]]\n",
    "perturbations_without_bing = [(delete_characters, False, 'delete_characters'), (replace_characters, False, 'replace_characters'), (add_characters, False, 'add_characters')]\n",
    "attributes_without_bing = [\"Robustness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def M_ASR_without_Bing(models, perturbations, attributes):\n",
    "    RESULTS = pd.DataFrame(columns=[\"Value\", \"Time\"])\n",
    "    for model in models:\n",
    "        for perturbation in perturbations:\n",
    "            for attribute in attributes:\n",
    "                print(model[0], model[1], perturbation[2], attribute)\n",
    "                M, ASR = await calculate_M_ASR_without_Bing(model, perturbation[0], attribute, perturbation[1], iterations = 1)\n",
    "                print(M, ASR)\n",
    "                RESULTS.loc[model[0] + \" - \" + model[1] + \" - \" + perturbation[2] + \" - \" + attribute] = [M, ASR]\n",
    "\n",
    "    return RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarize facebook/bart-large-cnn delete_characters Robustness\n",
      "A naive hustler travels from Texas to New York City to seek personal fortune. He finds a new friend in the process, and a new way to make money. The pair meet up for the first time in New York's SoHo neighborhood. The two become friends, and the pair travel together for the rest of the trip.\n",
      "CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Visit CNN.com/Travel each week for a new gallery of snapshots from around the world. Visit www.dailymail.co.uk/travel for a latest gallery of photos.\n",
      "[\"A naive hustler travels from Texas to New York City to seek personal fortune. He finds a new friend in the process, and a new way to make money. The pair meet up for the first time in New York's SoHo neighborhood. The two become friends, and the pair travel together for the rest of the trip.\", 'CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Visit CNN.com/Travel each week for a new gallery of snapshots from around the world. Visit www.dailymail.co.uk/travel for a latest gallery of photos.']\n",
      "0.0 8.248263835906982\n",
      "summarize facebook/bart-large-cnn replace_characters Robustness\n"
     ]
    }
   ],
   "source": [
    "summarize_results = await M_ASR_without_Bing(models_summarize, perturbations_without_bing, attributes_without_bing)\n",
    "summarize_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic s-nlp/roberta_toxicity_classifier delete_characters Robustness\n",
      "1.0 23.209882736206055\n",
      "toxic s-nlp/roberta_toxicity_classifier replace_characters Robustness\n",
      "1.0 1.7736492156982422\n",
      "toxic s-nlp/roberta_toxicity_classifier add_characters Robustness\n",
      "1.0 2.0148849487304688\n",
      "toxic s-nlp/roberta_toxicity_classifier delete_sentences Robustness\n",
      "1.0 1.8481709957122803\n",
      "toxic citizenlab/distilbert-base-multilingual-cased-toxicity delete_characters Robustness\n",
      "1.0 23.87169098854065\n",
      "toxic citizenlab/distilbert-base-multilingual-cased-toxicity replace_characters Robustness\n",
      "1.0 1.7100698947906494\n",
      "toxic citizenlab/distilbert-base-multilingual-cased-toxicity add_characters Robustness\n",
      "0.0 2.025097370147705\n",
      "toxic citizenlab/distilbert-base-multilingual-cased-toxicity delete_sentences Robustness\n",
      "1.0 1.7129030227661133\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>23.209883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.773649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.014885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.848171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>23.871691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.710070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.025097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.712903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Value       Time\n",
       "0    1.0  23.209883\n",
       "1    1.0   1.773649\n",
       "2    1.0   2.014885\n",
       "3    1.0   1.848171\n",
       "4    1.0  23.871691\n",
       "5    1.0   1.710070\n",
       "6    0.0   2.025097\n",
       "7    1.0   1.712903"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_results = await M_ASR_without_Bing(models_toxic, perturbations_without_bing, attributes_without_bing)\n",
    "toxic_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam h-e-l-l-o/email-spam-classification-merged delete_characters Robustness\n",
      "1.0 1.2653450965881348\n",
      "spam h-e-l-l-o/email-spam-classification-merged replace_characters Robustness\n",
      "1.0 1.2148048877716064\n",
      "spam h-e-l-l-o/email-spam-classification-merged add_characters Robustness\n",
      "1.0 1.506814956665039\n",
      "spam h-e-l-l-o/email-spam-classification-merged delete_sentences Robustness\n",
      "1.0 1.4900460243225098\n",
      "spam dima806/email-spam-detection-roberta delete_characters Robustness\n",
      "1.0 22.97094202041626\n",
      "spam dima806/email-spam-detection-roberta replace_characters Robustness\n",
      "1.0 1.158202886581421\n",
      "spam dima806/email-spam-detection-roberta add_characters Robustness\n",
      "1.0 1.3632292747497559\n",
      "spam dima806/email-spam-detection-roberta delete_sentences Robustness\n",
      "1.0 1.1460521221160889\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spam - h-e-l-l-o/email-spam-classification-merged - delete_characters - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.265345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam - h-e-l-l-o/email-spam-classification-merged - replace_characters - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.214805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam - h-e-l-l-o/email-spam-classification-merged - add_characters - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.506815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam - h-e-l-l-o/email-spam-classification-merged - delete_sentences - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.490046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam - dima806/email-spam-detection-roberta - delete_characters - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.970942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam - dima806/email-spam-detection-roberta - replace_characters - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.158203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam - dima806/email-spam-detection-roberta - add_characters - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.363229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam - dima806/email-spam-detection-roberta - delete_sentences - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.146052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Value       Time\n",
       "spam - h-e-l-l-o/email-spam-classification-merg...    1.0   1.265345\n",
       "spam - h-e-l-l-o/email-spam-classification-merg...    1.0   1.214805\n",
       "spam - h-e-l-l-o/email-spam-classification-merg...    1.0   1.506815\n",
       "spam - h-e-l-l-o/email-spam-classification-merg...    1.0   1.490046\n",
       "spam - dima806/email-spam-detection-roberta - d...    1.0  22.970942\n",
       "spam - dima806/email-spam-detection-roberta - r...    1.0   1.158203\n",
       "spam - dima806/email-spam-detection-roberta - a...    1.0   1.363229\n",
       "spam - dima806/email-spam-detection-roberta - d...    1.0   1.146052"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_results = await M_ASR_without_Bing(models_spam, perturbations_without_bing, attributes_without_bing)\n",
    "spam_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate t5-base delete_characters Robustness\n",
      "Die Besatzung des Schiffes Serenity versucht, einem telepathischen Attentäter zu entkommen.\n",
      "Die Besatzung der shi Serenit versucht, einem Mörder zu entgehen, der elepathisch ist.\n",
      "['Die Besatzung des Schiffes Serenity versucht, einem telepathischen Attentäter zu entkommen.', 'Die Besatzung der shi Serenit versucht, einem Mörder zu entgehen, der elepathisch ist.']\n",
      "1.0 5.5460169315338135\n",
      "translate t5-base replace_characters Robustness\n",
      "Ein Polizeidetektiv, ein Bankräuber und ein mächtiger Makler treten nach dem glänzenden Raub des Kriminellen in eine Geiselsituation.\n",
      "Ein uolice detectivL, ein Bankrobher, Xnd ein hoch-pmwer brokea in hoch-stakas negotiaTions afUer die brilliknt heist spVrals des Kriminellen in eine hostEge siTuation.\n",
      "['Ein Polizeidetektiv, ein Bankräuber und ein mächtiger Makler treten nach dem glänzenden Raub des Kriminellen in eine Geiselsituation.', 'Ein uolice detectivL, ein Bankrobher, Xnd ein hoch-pmwer brokea in hoch-stakas negotiaTions afUer die brilliknt heist spVrals des Kriminellen in eine hostEge siTuation.']\n",
      "0.0 16.15082097053528\n",
      "translate t5-base add_characters Robustness\n",
      "In den Vereinigten Staaten im Vorgebirge wird Solomon Northup, ein freier schwarzer Mann aus dem Hochstaat New York, entführt und in die Sklaverei verkauft.\n",
      "Soilomon Northup, ein freier schwarzer Mann aus dem Upstoate New YoUrk, ist in den Vereinigten Staaten von Antebellum iCnto Sklaverei verkauft.\n",
      "['In den Vereinigten Staaten im Vorgebirge wird Solomon Northup, ein freier schwarzer Mann aus dem Hochstaat New York, entführt und in die Sklaverei verkauft.', 'Soilomon Northup, ein freier schwarzer Mann aus dem Upstoate New YoUrk, ist in den Vereinigten Staaten von Antebellum iCnto Sklaverei verkauft.']\n",
      "1.0 13.781719207763672\n",
      "translate t5-base delete_sentences Robustness\n",
      "The story of a team of female African-American mathematicians who served a vital role in NASA during the early years of the U.S.\n",
      "The story of a team of female African-American mathematicians who served a vital role in NASA during the early years of the U.S.\n",
      "['The story of a team of female African-American mathematicians who served a vital role in NASA during the early years of the U.S.', 'The story of a team of female African-American mathematicians who served a vital role in NASA during the early years of the U.S.']\n",
      "1.0 4.946159839630127\n",
      "translate allenai/wmt16-en-de-12-1 delete_characters Robustness\n",
      "Eine Familie, die entschlossen ist, ihre junge Tochter ins Finale eines Beautyfregeant zu bringen, nimmt mit ihrem VW-Bus eine Kreuzung -@ country trip mit dem VW-Bus.\n",
      "Eine Hungersnot entschlossen, die jungen Töchter ito th finale einer Schönheit heidnischen nehmen Sie eine Kreuzung -@ cuntry trip i Erbe VW uns.\n",
      "['Eine Familie, die entschlossen ist, ihre junge Tochter ins Finale eines Beautyfregeant zu bringen, nimmt mit ihrem VW-Bus eine Kreuzung -@ country trip mit dem VW-Bus.', 'Eine Hungersnot entschlossen, die jungen Töchter ito th finale einer Schönheit heidnischen nehmen Sie eine Kreuzung -@ cuntry trip i Erbe VW uns.']\n",
      "0.0 13.022063255310059\n",
      "translate allenai/wmt16-en-de-12-1 replace_characters Robustness\n",
      "Eine alternde, explosive -@ addled father macht die Reise von Montana nach Nebraska seinen entfremdeten Sohn in Order um eine Million -@ dollar Mega Sweepstakes Marketing Preis zu beanspruchen.\n",
      "Ein alterndes, boozx -@ dollau Mega SweepstakeA macht das TriL von MontanZ So Nesraska yith hWs eitranged Sohn in order zu claum eine Million -@ dollau Mega SweepstakeA Marketing Preis.\n",
      "['Eine alternde, explosive -@ addled father macht die Reise von Montana nach Nebraska seinen entfremdeten Sohn in Order um eine Million -@ dollar Mega Sweepstakes Marketing Preis zu beanspruchen.', 'Ein alterndes, boozx -@ dollau Mega SweepstakeA macht das TriL von MontanZ So Nesraska yith hWs eitranged Sohn in order zu claum eine Million -@ dollau Mega SweepstakeA Marketing Preis.']\n",
      "0.0 2.453343152999878\n",
      "translate allenai/wmt16-en-de-12-1 add_characters Robustness\n",
      "Sein früheres Leben und Karriere von Vito Corleone in den 1920er Jahren in New York City wird dargestellt, während sein Sohn Michael seinen Einfluss auf das Syndikat für Familienkriminalität ausweitet und verschärft.\n",
      "The earAly life anhd Karriere Jof QVitoFg Corleone in 1920s NewF Yorkr City wird dargestellt, wQlhile seinen Sohn Michael, erforscht und tiLghtens sein Bgrip oan thGe Familienkriminalität syndiGcate.\n",
      "['Sein früheres Leben und Karriere von Vito Corleone in den 1920er Jahren in New York City wird dargestellt, während sein Sohn Michael seinen Einfluss auf das Syndikat für Familienkriminalität ausweitet und verschärft.', 'The earAly life anhd Karriere Jof QVitoFg Corleone in 1920s NewF Yorkr City wird dargestellt, wQlhile seinen Sohn Michael, erforscht und tiLghtens sein Bgrip oan thGe Familienkriminalität syndiGcate.']\n",
      "0.0 2.3201868534088135\n",
      "translate allenai/wmt16-en-de-12-1 delete_sentences Robustness\n",
      "Ein Elite-Counter -@ Nachrichtendienst erfährt von einer Handlung, die von einem Maniacal beherrscht wird.\n",
      "Ein Elite-Counter -@ Nachrichtendienst erfährt von einer Handlung, die von einem Maniacal beherrscht wird.\n",
      "['Ein Elite-Counter -@ Nachrichtendienst erfährt von einer Handlung, die von einem Maniacal beherrscht wird.', 'Ein Elite-Counter -@ Nachrichtendienst erfährt von einer Handlung, die von einem Maniacal beherrscht wird.']\n",
      "1.0 1.4715490341186523\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>translate - t5-base - delete_characters - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.546017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>translate - t5-base - replace_characters - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.150821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>translate - t5-base - add_characters - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.781719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>translate - t5-base - delete_sentences - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.946160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>translate - allenai/wmt16-en-de-12-1 - delete_characters - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.022063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>translate - allenai/wmt16-en-de-12-1 - replace_characters - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.453343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>translate - allenai/wmt16-en-de-12-1 - add_characters - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.320187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>translate - allenai/wmt16-en-de-12-1 - delete_sentences - Robustness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.471549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Value       Time\n",
       "translate - t5-base - delete_characters - Robus...    1.0   5.546017\n",
       "translate - t5-base - replace_characters - Robu...    0.0  16.150821\n",
       "translate - t5-base - add_characters - Robustness     1.0  13.781719\n",
       "translate - t5-base - delete_sentences - Robust...    1.0   4.946160\n",
       "translate - allenai/wmt16-en-de-12-1 - delete_c...    0.0  13.022063\n",
       "translate - allenai/wmt16-en-de-12-1 - replace_...    0.0   2.453343\n",
       "translate - allenai/wmt16-en-de-12-1 - add_char...    0.0   2.320187\n",
       "translate - allenai/wmt16-en-de-12-1 - delete_s...    1.0   1.471549"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_results = await M_ASR_without_Bing(models_translate, perturbations_without_bing, attributes_without_bing)\n",
    "translate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fillmask vinai/bertweet-base delete_characters Robustness\n",
      "indexes_to_delete [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 30, 31, 32, 33]\n",
      "mask_index 29\n",
      "Antes [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 30, 31, 32, 33]\n",
      "Despues [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 31, 32, 33]\n",
      "Antes [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 31, 32, 33]\n",
      "Despues [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 32, 33]\n",
      "Antes [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 32, 33]\n",
      "Despues [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 33]\n",
      "Antes [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 33]\n",
      "Despues [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27]\n",
      "indexes_to_delete2 [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27]\n",
      "Original input: The currency of Japan is the <mask>.\n",
      "Perturbed input: The currency of Japan  the <mask>.\n",
      "Output 1: [{'score': 0.49970299005508423, 'token': 23812, 'token_str': 'yen', 'sequence': 'The currency of Japan is the yen.'}, {'score': 0.2708187699317932, 'token': 4165, 'token_str': 'dollar', 'sequence': 'The currency of Japan is the dollar.'}, {'score': 0.04920639470219612, 'token': 50188, 'token_str': 'Yen', 'sequence': 'The currency of Japan is the Yen.'}, {'score': 0.026750043034553528, 'token': 8988, 'token_str': 'pound', 'sequence': 'The currency of Japan is the pound.'}, {'score': 0.015674391761422157, 'token': 10009, 'token_str': 'Dollar', 'sequence': 'The currency of Japan is the Dollar.'}]\n",
      "Output 2: [{'score': 0.2220313400030136, 'token': 23812, 'token_str': 'yen', 'sequence': 'The currency of Japan the yen.'}, {'score': 0.19166143238544464, 'token': 4165, 'token_str': 'dollar', 'sequence': 'The currency of Japan the dollar.'}, {'score': 0.03633290156722069, 'token': 50188, 'token_str': 'Yen', 'sequence': 'The currency of Japan the Yen.'}, {'score': 0.030713975429534912, 'token': 12357, 'token_str': 'currency', 'sequence': 'The currency of Japan the currency.'}, {'score': 0.021336881443858147, 'token': 10009, 'token_str': 'Dollar', 'sequence': 'The currency of Japan the Dollar.'}]\n",
      "0.0 1.1830370426177979\n",
      "fillmask vinai/bertweet-base replace_characters Robustness\n",
      "Original input: The architectural masterpiece located in India and known as the 'City of Victory' is <mask>.\n",
      "Perturbed input: The architectuvJl masterpFece lacJted in India and known as tte 'City of Victory' is <mask>.\n",
      "Output 1: [{'score': 0.05533524975180626, 'token': 137, 'token_str': 'here', 'sequence': \"The architectural masterpiece located in India and known as the 'City of Victory' is here.\"}, {'score': 0.03941173851490021, 'token': 27295, 'token_str': 'preserved', 'sequence': \"The architectural masterpiece located in India and known as the 'City of Victory' is preserved.\"}, {'score': 0.030728835612535477, 'token': 11710, 'token_str': 'celebrated', 'sequence': \"The architectural masterpiece located in India and known as the 'City of Victory' is celebrated.\"}, {'score': 0.025194698944687843, 'token': 3185, 'token_str': 'completed', 'sequence': \"The architectural masterpiece located in India and known as the 'City of Victory' is completed.\"}, {'score': 0.025113459676504135, 'token': 21041, 'token_str': 'magnificent', 'sequence': \"The architectural masterpiece located in India and known as the 'City of Victory' is magnificent.\"}]\n",
      "Output 2: [{'score': 0.061425816267728806, 'token': 128, 'token_str': 'today', 'sequence': \"The architectuvJl masterpFece lacJted in India and known as tte 'City of Victory' is today.\"}, {'score': 0.04449830576777458, 'token': 27295, 'token_str': 'preserved', 'sequence': \"The architectuvJl masterpFece lacJted in India and known as tte 'City of Victory' is preserved.\"}, {'score': 0.037985701113939285, 'token': 137, 'token_str': 'here', 'sequence': \"The architectuvJl masterpFece lacJted in India and known as tte 'City of Victory' is here.\"}, {'score': 0.03086768463253975, 'token': 1726, 'token_str': 'present', 'sequence': \"The architectuvJl masterpFece lacJted in India and known as tte 'City of Victory' is present.\"}, {'score': 0.029071228578686714, 'token': 1024, 'token_str': 'known', 'sequence': \"The architectuvJl masterpFece lacJted in India and known as tte 'City of Victory' is known.\"}]\n",
      "0.0 1.1574327945709229\n",
      "fillmask vinai/bertweet-base add_characters Robustness\n",
      "Original input: The composer of the famous 'Ode to Joy' featured in Beethoven's Symphony No. 9 is <mask>.\n",
      "Perturbed input: The composerG of the fsamouPs 'Ode to Joy' featured Oin BcveetOhoven's SymphoOny No. 9 is <mask>.\n",
      "Output 1: [{'score': 0.08827667683362961, 'token': 6229, 'token_str': 'unknown', 'sequence': \"The composer of the famous 'Ode to Joy' featured in Beethoven's Symphony No. 9 is unknown.\"}, {'score': 0.023478152230381966, 'token': 1094, 'token_str': 'born', 'sequence': \"The composer of the famous 'Ode to Joy' featured in Beethoven's Symphony No. 9 is born.\"}, {'score': 0.02325870469212532, 'token': 1285, 'token_str': 'English', 'sequence': \"The composer of the famous 'Ode to Joy' featured in Beethoven's Symphony No. 9 is English.\"}, {'score': 0.020431630313396454, 'token': 237, 'token_str': 'also', 'sequence': \"The composer of the famous 'Ode to Joy' featured in Beethoven's Symphony No. 9 is also.\"}, {'score': 0.01830238848924637, 'token': 1024, 'token_str': 'known', 'sequence': \"The composer of the famous 'Ode to Joy' featured in Beethoven's Symphony No. 9 is known.\"}]\n",
      "Output 2: [{'score': 0.10911434888839722, 'token': 6229, 'token_str': 'unknown', 'sequence': \"The composerG of the fsamouPs 'Ode to Joy' featured Oin BcveetOhoven's SymphoOny No. 9 is unknown.\"}, {'score': 0.017858652397990227, 'token': 1024, 'token_str': 'known', 'sequence': \"The composerG of the fsamouPs 'Ode to Joy' featured Oin BcveetOhoven's SymphoOny No. 9 is known.\"}, {'score': 0.01733894646167755, 'token': 3280, 'token_str': 'included', 'sequence': \"The composerG of the fsamouPs 'Ode to Joy' featured Oin BcveetOhoven's SymphoOny No. 9 is included.\"}, {'score': 0.017179332673549652, 'token': 372, 'token_str': 'used', 'sequence': \"The composerG of the fsamouPs 'Ode to Joy' featured Oin BcveetOhoven's SymphoOny No. 9 is used.\"}, {'score': 0.01631752960383892, 'token': 1726, 'token_str': 'present', 'sequence': \"The composerG of the fsamouPs 'Ode to Joy' featured Oin BcveetOhoven's SymphoOny No. 9 is present.\"}]\n",
      "0.0 1.1602959632873535\n",
      "fillmask roberta-base delete_characters Robustness\n",
      "indexes_to_delete [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 42, 43, 44, 45, 48, 49, 50]\n",
      "mask_index 41\n",
      "Antes [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 42, 43, 44, 45, 48, 49, 50]\n",
      "Despues [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 43, 44, 45, 48, 49, 50]\n",
      "Antes [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 43, 44, 45, 48, 49, 50]\n",
      "Despues [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 44, 45, 48, 49, 50]\n",
      "Antes [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 44, 45, 48, 49, 50]\n",
      "Despues [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 45, 48, 49, 50]\n",
      "Antes [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 45, 48, 49, 50]\n",
      "Despues [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 48, 49, 50]\n",
      "indexes_to_delete2 [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 48, 49, 50]\n",
      "Original input: The author of 'To Kill a Mockingbird' is <mask> Lee.\n",
      "Perturbed input: The autho f 'To Kill a Mockigbird' is <mask> Lee.\n",
      "Output 1: [{'score': 0.9498092532157898, 'token': 9266, 'token_str': ' Harper', 'sequence': \"The author of 'To Kill a Mockingbird' is Harper Lee.\"}, {'score': 0.012723179534077644, 'token': 31808, 'token_str': ' Spike', 'sequence': \"The author of 'To Kill a Mockingbird' is Spike Lee.\"}, {'score': 0.008627476170659065, 'token': 8995, 'token_str': ' Stan', 'sequence': \"The author of 'To Kill a Mockingbird' is Stan Lee.\"}, {'score': 0.005306977313011885, 'token': 5469, 'token_str': ' Christopher', 'sequence': \"The author of 'To Kill a Mockingbird' is Christopher Lee.\"}, {'score': 0.003368915757164359, 'token': 7413, 'token_str': ' Ang', 'sequence': \"The author of 'To Kill a Mockingbird' is Ang Lee.\"}]\n",
      "Output 2: [{'score': 0.0506284162402153, 'token': 5469, 'token_str': ' Christopher', 'sequence': \"The autho f 'To Kill a Mockigbird' is Christopher Lee.\"}, {'score': 0.04327232763171196, 'token': 5409, 'token_str': ' Bruce', 'sequence': \"The autho f 'To Kill a Mockigbird' is Bruce Lee.\"}, {'score': 0.040541838854551315, 'token': 9266, 'token_str': ' Harper', 'sequence': \"The autho f 'To Kill a Mockigbird' is Harper Lee.\"}, {'score': 0.03167731687426567, 'token': 1738, 'token_str': ' Robert', 'sequence': \"The autho f 'To Kill a Mockigbird' is Robert Lee.\"}, {'score': 0.026743751019239426, 'token': 31808, 'token_str': ' Spike', 'sequence': \"The autho f 'To Kill a Mockigbird' is Spike Lee.\"}]\n",
      "0.0 1.9318819046020508\n",
      "fillmask roberta-base replace_characters Robustness\n",
      "Original input: The ancient city of Rome was founded, according to legend, by twin brothers Romulus and <mask>.\n",
      "Perturbed input: The acGient ciby of Oome was founded, accorLing to legend, by twin bFothers Romuuus and <mask>.\n",
      "Output 1: [{'score': 0.15716393291950226, 'token': 40442, 'token_str': ' Cato', 'sequence': 'The ancient city of Rome was founded, according to legend, by twin brothers Romulus and Cato.'}, {'score': 0.1298162043094635, 'token': 28042, 'token_str': ' Caesar', 'sequence': 'The ancient city of Rome was founded, according to legend, by twin brothers Romulus and Caesar.'}, {'score': 0.08742336183786392, 'token': 20487, 'token_str': ' Julius', 'sequence': 'The ancient city of Rome was founded, according to legend, by twin brothers Romulus and Julius.'}, {'score': 0.07161041349172592, 'token': 12520, 'token_str': ' Leo', 'sequence': 'The ancient city of Rome was founded, according to legend, by twin brothers Romulus and Leo.'}, {'score': 0.0687948539853096, 'token': 42352, 'token_str': ' Augustus', 'sequence': 'The ancient city of Rome was founded, according to legend, by twin brothers Romulus and Augustus.'}]\n",
      "Output 2: [{'score': 0.0377470999956131, 'token': 46752, 'token_str': ' Lucius', 'sequence': 'The acGient ciby of Oome was founded, accorLing to legend, by twin bFothers Romuuus and Lucius.'}, {'score': 0.034415602684020996, 'token': 7380, 'token_str': ' Marcus', 'sequence': 'The acGient ciby of Oome was founded, accorLing to legend, by twin bFothers Romuuus and Marcus.'}, {'score': 0.01454966701567173, 'token': 610, 'token_str': ' John', 'sequence': 'The acGient ciby of Oome was founded, accorLing to legend, by twin bFothers Romuuus and John.'}, {'score': 0.009040454402565956, 'token': 34081, 'token_str': ' Magnus', 'sequence': 'The acGient ciby of Oome was founded, accorLing to legend, by twin bFothers Romuuus and Magnus.'}, {'score': 0.008485888130962849, 'token': 38688, 'token_str': ' Hercules', 'sequence': 'The acGient ciby of Oome was founded, accorLing to legend, by twin bFothers Romuuus and Hercules.'}]\n",
      "0.0 2.5810937881469727\n",
      "fillmask roberta-base add_characters Robustness\n",
      "Original input: The ancient wonder known for its hanging gardens is the <mask> of Babylon.\n",
      "Perturbed input: The ancientzS wonder known for itGs haXngings gpardens is the <mask> of CBabylon.\n",
      "Output 1: [{'score': 0.26382124423980713, 'token': 343, 'token_str': ' city', 'sequence': 'The ancient wonder known for its hanging gardens is the city of Babylon.'}, {'score': 0.13473926484584808, 'token': 6081, 'token_str': ' Garden', 'sequence': 'The ancient wonder known for its hanging gardens is the Garden of Babylon.'}, {'score': 0.0979059636592865, 'token': 5671, 'token_str': ' garden', 'sequence': 'The ancient wonder known for its hanging gardens is the garden of Babylon.'}, {'score': 0.05694554001092911, 'token': 9660, 'token_str': ' Temple', 'sequence': 'The ancient wonder known for its hanging gardens is the Temple of Babylon.'}, {'score': 0.049193788319826126, 'token': 12222, 'token_str': ' Gardens', 'sequence': 'The ancient wonder known for its hanging gardens is the Gardens of Babylon.'}]\n",
      "Output 2: [{'score': 0.04555308073759079, 'token': 9069, 'token_str': ' god', 'sequence': 'The ancientzS wonder known for itGs haXngings gpardens is the god of CBabylon.'}, {'score': 0.01823466084897518, 'token': 36679, 'token_str': ' pearl', 'sequence': 'The ancientzS wonder known for itGs haXngings gpardens is the pearl of CBabylon.'}, {'score': 0.016535626724362373, 'token': 766, 'token_str': ' name', 'sequence': 'The ancientzS wonder known for itGs haXngings gpardens is the name of CBabylon.'}, {'score': 0.01407426968216896, 'token': 7763, 'token_str': ' oldest', 'sequence': 'The ancientzS wonder known for itGs haXngings gpardens is the oldest of CBabylon.'}, {'score': 0.013136012479662895, 'token': 28021, 'token_str': ' dragon', 'sequence': 'The ancientzS wonder known for itGs haXngings gpardens is the dragon of CBabylon.'}]\n",
      "0.0 2.073338270187378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fillmask - vinai/bertweet-base - delete_characters - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.183037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fillmask - vinai/bertweet-base - replace_characters - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.157433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fillmask - vinai/bertweet-base - add_characters - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.160296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fillmask - roberta-base - delete_characters - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.931882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fillmask - roberta-base - replace_characters - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.581094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fillmask - roberta-base - add_characters - Robustness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.073338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Value      Time\n",
       "fillmask - vinai/bertweet-base - delete_charact...    0.0  1.183037\n",
       "fillmask - vinai/bertweet-base - replace_charac...    0.0  1.157433\n",
       "fillmask - vinai/bertweet-base - add_characters...    0.0  1.160296\n",
       "fillmask - roberta-base - delete_characters - R...    0.0  1.931882\n",
       "fillmask - roberta-base - replace_characters - ...    0.0  2.581094\n",
       "fillmask - roberta-base - add_characters - Robu...    0.0  2.073338"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_masks_results = await M_ASR_without_Bing(models_fillmask, perturbations_without_bing, attributes_without_bing)\n",
    "fill_masks_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
